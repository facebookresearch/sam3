{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trainer\n",
    "\n",
    "# <a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/sam3/blob/main/notebooks/sam3_image_multiway_prompting.ipynb\">\n",
    "#   <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "# </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"Torchvision version:\", torchvision.__version__)\n",
    "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install opencv-python matplotlib scikit-learn\n",
    "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/sam3.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1389103906143178,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "sam3_root = \"/home/kalyanv/sam3\"\n",
    "sys.path.append(f\"{sam3_root}/examples\")\n",
    "\n",
    "from utils import draw_box_on_image, show_img_tensor, plot_bbox, plot_mask, COLORS, plot_results, normalize_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# turn on tfloat32 for Ampere GPUs\n",
    "# https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# use bfloat16 for the entire notebook\n",
    "torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 785101161160169,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "from sam3 import build_sam3_image_model\n",
    "\n",
    "bpe_path = f\"{sam3_root}/assets/bpe_simple_vocab_16e6.txt.gz\"\n",
    "checkpoint_path = f\"{sam3_root}/assets/checkpoints/paper_ckpt_model_only_from_fair_sc.pt\"\n",
    "model = build_sam3_image_model(bpe_path=bpe_path, checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "\n",
    "image_path = f\"{sam3_root}/assets/images/test_image.jpg\"\n",
    "image = Image.open(image_path)\n",
    "width, height = image.size\n",
    "processor = Sam3Processor(model, confidence_threshold=0.5)\n",
    "inference_state = processor.set_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual prompt (Box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 4344515869113686,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "box_input_xywh = [480.0, 290.0, 110.0 , 360.0] # Here the point is in top-left corner, w, h format.\n",
    "\n",
    "\n",
    "norm_box_xywh = box_input_xywh / np.array([width, height, width, height], dtype=np.float32).reshape(1,-1)\n",
    "print(\"Normalized box:\", norm_box_xywh)\n",
    "\n",
    "processor.reset_all_prompts(inference_state)\n",
    "inference_state = processor.add_geometric_prompt(state=inference_state, box=normalize_bbox(box_input_xywh, width, height), label=True)\n",
    "\n",
    "img0 = Image.open(image_path)\n",
    "image_with_box = draw_box_on_image(img0, box_input_xywh )\n",
    "plt.imshow(image_with_box)\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1972454793596108,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "plot_results(img0, inference_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-box prompting (with positive and negative boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1157754466299886,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "box_input_xywh = [[480.0, 290.0, 110.0 , 360.0],[370.0, 280.0, 115.0 , 375.0]]\n",
    "box_labels = [True, False]\n",
    "\n",
    "print(\"Normalized box:\", norm_box_xywh)\n",
    "processor.reset_all_prompts(inference_state)\n",
    "\n",
    "for box, label in zip(box_input_xywh, box_labels):\n",
    "    inference_state = processor.add_geometric_prompt(state=inference_state, box=normalize_bbox(box, width, height), label=label)\n",
    "\n",
    "img0 = Image.open(image_path)\n",
    "image_with_box = img0\n",
    "for i in range(len(box_input_xywh)):\n",
    "    if box_labels[i] == 1:\n",
    "        color = (0,255,0)\n",
    "    else:\n",
    "        color = (255,0,0)\n",
    "    image_with_box = draw_box_on_image(image_with_box, box_input_xywh[i],color )\n",
    "plt.imshow(image_with_box)\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1352849976506927,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "plot_results(img0, inference_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1888491128769570,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "processor.reset_all_prompts(inference_state)\n",
    "inference_state= processor.set_text_prompt(state =inference_state, prompt=\"shoe\")\n",
    "\n",
    "\n",
    "img0 = Image.open(image_path)\n",
    "plot_results(img0, inference_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileHeader": "",
  "fileUid": "ff722971-ca5d-431f-8450-ccfea4ff0708",
  "isAdHoc": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
