{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video prediction with SAM 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam3_root = \"/home/ronghanghu/workspace/sam3\"\n",
    "\n",
    "checkpoint_file = \"/checkpoint/sam3/ronghanghu/sam3_release/ckpts/sam3_video_model_only.pt\"\n",
    "has_presence_token = True\n",
    "geo_encoder_use_img_cross_attn = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# use all available GPUs on the machine\n",
    "gpus_to_use = range(torch.cuda.device_count())\n",
    "\n",
    "# # use only a single GPU\n",
    "# gpus_to_use = [torch.cuda.current_device()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "output": {
     "id": 1139615394365657,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:03,103 153519 sam3_video_predictor.py: 282:\u001b[0m using the following GPU IDs: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:03,104 153519 sam3_video_predictor.py: 298:\u001b[0m \n",
      "\n",
      "\n",
      "\t*** START loading model on all ranks ***\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:03,105 153519 sam3_video_predictor.py: 300:\u001b[0m loading model on rank=0 with world_size=8 -- this could take a while ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled the use of perflib.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:10,518 153519 sam3_video_base.py: 156:\u001b[0m `setting max_num_objects` to 128 -- creating num_obj_for_compile=16 objects for torch.compile cache\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:13,216 153519 sam3_video_predictor.py: 302:\u001b[0m loading model on rank=0 with world_size=8 -- DONE locally\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:13,217 153519 sam3_video_predictor.py: 359:\u001b[0m spawning 7 worker processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled the use of perflib.\n",
      "Enabled the use of perflib.\n",
      "Enabled the use of perflib.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:20,291 153723 sam3_video_predictor.py: 439:\u001b[0m starting worker process rank=2 with world_size=8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled the use of perflib.\n",
      "Enabled the use of perflib.\n",
      "Enabled the use of perflib.\n",
      "Enabled the use of perflib.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:20,974 153725 sam3_video_predictor.py: 439:\u001b[0m starting worker process rank=4 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:21,115 153726 sam3_video_predictor.py: 439:\u001b[0m starting worker process rank=5 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:21,416 153722 sam3_video_predictor.py: 439:\u001b[0m starting worker process rank=1 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:21,419 153723 sam3_video_predictor.py: 300:\u001b[0m loading model on rank=2 with world_size=8 -- this could take a while ...\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:21,603 153724 sam3_video_predictor.py: 439:\u001b[0m starting worker process rank=3 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:21,628 153728 sam3_video_predictor.py: 439:\u001b[0m starting worker process rank=7 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:21,634 153727 sam3_video_predictor.py: 439:\u001b[0m starting worker process rank=6 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:22,240 153725 sam3_video_predictor.py: 300:\u001b[0m loading model on rank=4 with world_size=8 -- this could take a while ...\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:22,381 153726 sam3_video_predictor.py: 300:\u001b[0m loading model on rank=5 with world_size=8 -- this could take a while ...\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:22,604 153728 sam3_video_predictor.py: 300:\u001b[0m loading model on rank=7 with world_size=8 -- this could take a while ...\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:22,646 153722 sam3_video_predictor.py: 300:\u001b[0m loading model on rank=1 with world_size=8 -- this could take a while ...\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:22,704 153727 sam3_video_predictor.py: 300:\u001b[0m loading model on rank=6 with world_size=8 -- this could take a while ...\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:53:22,725 153724 sam3_video_predictor.py: 300:\u001b[0m loading model on rank=3 with world_size=8 -- this could take a while ...\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:54:17,681 153723 sam3_video_base.py: 156:\u001b[0m `setting max_num_objects` to 128 -- creating num_obj_for_compile=16 objects for torch.compile cache\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:54:20,445 153726 sam3_video_base.py: 156:\u001b[0m `setting max_num_objects` to 128 -- creating num_obj_for_compile=16 objects for torch.compile cache\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:54:24,311 153725 sam3_video_base.py: 156:\u001b[0m `setting max_num_objects` to 128 -- creating num_obj_for_compile=16 objects for torch.compile cache\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:54:25,252 153727 sam3_video_base.py: 156:\u001b[0m `setting max_num_objects` to 128 -- creating num_obj_for_compile=16 objects for torch.compile cache\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:54:25,438 153728 sam3_video_base.py: 156:\u001b[0m `setting max_num_objects` to 128 -- creating num_obj_for_compile=16 objects for torch.compile cache\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:54:25,557 153724 sam3_video_base.py: 156:\u001b[0m `setting max_num_objects` to 128 -- creating num_obj_for_compile=16 objects for torch.compile cache\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:54:25,721 153722 sam3_video_base.py: 156:\u001b[0m `setting max_num_objects` to 128 -- creating num_obj_for_compile=16 objects for torch.compile cache\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:54:55,193 153723 sam3_video_predictor.py: 302:\u001b[0m loading model on rank=2 with world_size=8 -- DONE locally\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:54:55,193 153723 sam3_video_predictor.py: 448:\u001b[0m started worker rank=2 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:54:59,112 153726 sam3_video_predictor.py: 302:\u001b[0m loading model on rank=5 with world_size=8 -- DONE locally\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:54:59,112 153726 sam3_video_predictor.py: 448:\u001b[0m started worker rank=5 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:02,531 153727 sam3_video_predictor.py: 302:\u001b[0m loading model on rank=6 with world_size=8 -- DONE locally\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:02,531 153727 sam3_video_predictor.py: 448:\u001b[0m started worker rank=6 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:02,630 153725 sam3_video_predictor.py: 302:\u001b[0m loading model on rank=4 with world_size=8 -- DONE locally\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:02,630 153725 sam3_video_predictor.py: 448:\u001b[0m started worker rank=4 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,553 153724 sam3_video_predictor.py: 302:\u001b[0m loading model on rank=3 with world_size=8 -- DONE locally\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,553 153724 sam3_video_predictor.py: 448:\u001b[0m started worker rank=3 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,669 153722 sam3_video_predictor.py: 302:\u001b[0m loading model on rank=1 with world_size=8 -- DONE locally\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,669 153722 sam3_video_predictor.py: 448:\u001b[0m started worker rank=1 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,677 153728 sam3_video_predictor.py: 302:\u001b[0m loading model on rank=7 with world_size=8 -- DONE locally\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,677 153728 sam3_video_predictor.py: 448:\u001b[0m started worker rank=7 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,678 153519 sam3_video_predictor.py: 393:\u001b[0m spawned 7 worker processes\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,680 153722 sam3_video_predictor.py: 401:\u001b[0m starting NCCL process group on rank=1 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,681 153723 sam3_video_predictor.py: 401:\u001b[0m starting NCCL process group on rank=2 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,681 153724 sam3_video_predictor.py: 401:\u001b[0m starting NCCL process group on rank=3 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,682 153725 sam3_video_predictor.py: 401:\u001b[0m starting NCCL process group on rank=4 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,682 153726 sam3_video_predictor.py: 401:\u001b[0m starting NCCL process group on rank=5 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,683 153519 sam3_video_predictor.py: 401:\u001b[0m starting NCCL process group on rank=0 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,683 153727 sam3_video_predictor.py: 401:\u001b[0m starting NCCL process group on rank=6 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:03,683 153728 sam3_video_predictor.py: 401:\u001b[0m starting NCCL process group on rank=7 with world_size=8\n",
      "[W1002 22:55:03.794243234 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "[W1002 22:55:03.794248894 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "[W1002 22:55:03.794326688 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "[W1002 22:55:03.794425674 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "[W1002 22:55:03.794417804 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "[W1002 22:55:03.794561332 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "[W1002 22:55:03.794619195 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "[W1002 22:55:03.794820036 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCCL version 2.25.1+cuda12.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:06,212 153519 sam3_video_predictor.py: 412:\u001b[0m started NCCL process group on rank=0 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:06,212 153725 sam3_video_predictor.py: 412:\u001b[0m started NCCL process group on rank=4 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:06,212 153723 sam3_video_predictor.py: 412:\u001b[0m started NCCL process group on rank=2 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:06,212 153722 sam3_video_predictor.py: 412:\u001b[0m started NCCL process group on rank=1 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:06,212 153727 sam3_video_predictor.py: 412:\u001b[0m started NCCL process group on rank=6 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:06,212 153724 sam3_video_predictor.py: 412:\u001b[0m started NCCL process group on rank=3 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:06,212 153728 sam3_video_predictor.py: 412:\u001b[0m started NCCL process group on rank=7 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:06,212 153726 sam3_video_predictor.py: 412:\u001b[0m started NCCL process group on rank=5 with world_size=8\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:06,213 153519 sam3_video_predictor.py: 313:\u001b[0m \n",
      "\n",
      "\n",
      "\t*** DONE loading model on all ranks ***\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sam3.model.sam3_video_predictor import Sam3VideoPredictorMultiGPU\n",
    "\n",
    "predictor = Sam3VideoPredictorMultiGPU(\n",
    "    checkpoint_path=checkpoint_file,\n",
    "    has_presence_token=has_presence_token,\n",
    "    geo_encoder_use_img_cross_attn=geo_encoder_use_img_cross_attn,\n",
    "    gpus_to_use=gpus_to_use,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "output": {
     "id": 1550465159251583,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 5000 RGB samples to LAB color space...\n",
      "Conversion to LAB complete.\n",
      "Fitting KMeans with 128 clusters on 5000 samples...\n",
      "KMeans fitting complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import visualize_formatted_frame_output, prepare_masks_for_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this video has 6 objects\n",
    "video_frames_dir = f\"{sam3_root}/assets/videos/0001\"\n",
    "prompt_text_str = \"person\"\n",
    "\n",
    "# this video has ~80 objects\n",
    "# video_frames_dir = \"/checkpoint/sam3/shared/webdemo/data/ta/static/gallery/selected_examples/0018/rgb\"\n",
    "# prompt_text_str = \"horse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \"image_files\" for visualization purposes (they are not used by the model)\n",
    "image_files = glob.glob(os.path.join(video_frames_dir, \"*.jpg\"))\n",
    "try:\n",
    "    # integer sort instead of string sort (so that e.g. \"2.jpg\" is before \"11.jpg\")\n",
    "    image_files.sort(key=lambda p: int(os.path.splitext(os.path.basename(p))[0]))\n",
    "except ValueError:\n",
    "    # fallback to lexicographic sort if the format is not \"<frame_index>.jpg\"\n",
    "    print(\n",
    "        f'frame names are not in \"<frame_index>.jpg\" format: {image_files[:5]=}, '\n",
    "        f\"falling back to lexicographic sort.\"\n",
    "    )\n",
    "    image_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening an inference session on this video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 24791498893803470,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:09,523 153722 sam3_video_predictor.py: 468:\u001b[0m worker rank=1 received request request['type']='start_session'\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:09,524 153727 sam3_video_predictor.py: 468:\u001b[0m worker rank=6 received request request['type']='start_session'\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:09,524 153723 sam3_video_predictor.py: 468:\u001b[0m worker rank=2 received request request['type']='start_session'\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:09,524 153726 sam3_video_predictor.py: 468:\u001b[0m worker rank=5 received request request['type']='start_session'\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:09,524 153725 sam3_video_predictor.py: 468:\u001b[0m worker rank=4 received request request['type']='start_session'\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:09,524 153728 sam3_video_predictor.py: 468:\u001b[0m worker rank=7 received request request['type']='start_session'\n",
      "\u001b[0m\u001b[32mINFO 2025-10-02 22:55:09,524 153724 sam3_video_predictor.py: 468:\u001b[0m worker rank=3 received request request['type']='start_session'\n",
      "frame loading (JPEG) [rank=7]:  76%|███████▌  | 205/270 [01:19<00:25,  2.55it/s]████████████████████████████████████████████████████████████▏                                     | 198/270 [01:19<00:27,  2.60it/s]"
     ]
    }
   ],
   "source": [
    "response = predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"start_session\",\n",
    "        resource_path=video_frames_dir,\n",
    "    )\n",
    ")\n",
    "session_id = response[\"session_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a text prompt on frame 0 and propagation throughout the video\n",
    "\n",
    "Note that the first call might be slower due to setting up buffers. **You can rerun all the cells below when measuring speed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1857140821887322,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "# note: in case you already ran one text prompt and now want to switch to another text prompt\n",
    "# it's required to reset the session first (otherwise the results would be wrong)\n",
    "_ = predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"reset_session\",\n",
    "        session_id=session_id,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1211259840810929,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "frame_idx = 0  # add a text prompt on frame 0\n",
    "response = predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"add_prompt\",\n",
    "        session_id=session_id,\n",
    "        frame_index=frame_idx,\n",
    "        text=prompt_text_str,\n",
    "    )\n",
    ")\n",
    "out = response[\"outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 2176083696212028,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "visualize_formatted_frame_output(\n",
    "    frame_idx,\n",
    "    image_files,\n",
    "    outputs_list=[prepare_masks_for_visualization({frame_idx: out})],\n",
    "    titles=[\"SAM 3 Dense Tracking outputs\"],\n",
    "    figsize=(6, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1292061085723685,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "# we will just propagate from frame 0 to the end of the video\n",
    "outputs_per_frame = {}\n",
    "for response in predictor.handle_stream_request(\n",
    "    request=dict(\n",
    "        type=\"propagate_in_video\",\n",
    "        session_id=session_id,\n",
    "    )\n",
    "):\n",
    "    outputs_per_frame[response[\"frame_index\"]] = response[\"outputs\"]\n",
    "\n",
    "outputs_per_frame = prepare_masks_for_visualization(outputs_per_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1329493578744396,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "vis_frame_stride = 60\n",
    "plt.close(\"all\")\n",
    "for frame_idx in range(0, len(outputs_per_frame), vis_frame_stride):\n",
    "    print(f\"frame {frame_idx}\")\n",
    "    visualize_formatted_frame_output(\n",
    "        frame_idx,\n",
    "        image_files,\n",
    "        outputs_list=[outputs_per_frame],\n",
    "        titles=[\"SAM 3 Dense Tracking outputs\"],\n",
    "        figsize=(6, 4),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, close the inference session to free its GPU resources\n",
    "# (you may start a new session on another video)\n",
    "_ = predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"close_session\",\n",
    "        session_id=session_id,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after all inference is done, we can shutdown the predictor\n",
    "# to free up the multi-GPU process group\n",
    "predictor.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileHeader": "",
  "fileUid": "0302644d-89e4-478b-b8e6-568ead852534",
  "isAdHoc": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
