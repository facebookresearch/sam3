{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video prediction with SAM 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam3_root = \"/home/ronghanghu/workspace/sam3\"\n",
    "\n",
    "# # prod v12 model (s3://fb-fair-onevision/ronghanghu/sam3_release/ckpts/prod_v12_sam2_internal_shared_dth0.5_newdet0.7_assth0.1_nms0.1.pt)\n",
    "# checkpoint_file = \"/checkpoint/sam3/ronghanghu/sam3_release/ckpts/prod_v12_sam2_internal_shared_dth0.5_newdet0.7_assth0.1_nms0.1.pt\"\n",
    "# has_presence_token = False\n",
    "# geo_encoder_use_img_cross_attn = False\n",
    "\n",
    "# prod v14 model (s3://fb-fair-onevision/ronghanghu/sam3_release/ckpts/sam3_v14_rc1.pt)\n",
    "checkpoint_file = \"/checkpoint/sam3/ronghanghu/sam3_release/ckpts/sam3_v14_rc1.pt\"\n",
    "has_presence_token = True\n",
    "geo_encoder_use_img_cross_attn = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# use all available GPUs on the machine\n",
    "gpus_to_use = range(torch.cuda.device_count())\n",
    "\n",
    "# # use only a single GPU\n",
    "# gpus_to_use = [torch.cuda.current_device()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1139615394365657,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "from sam3.model.sam3_video_predictor import Sam3VideoPredictorMultiGPU\n",
    "\n",
    "predictor = Sam3VideoPredictorMultiGPU(\n",
    "    checkpoint_path=checkpoint_file,\n",
    "    has_presence_token=has_presence_token,\n",
    "    geo_encoder_use_img_cross_attn=geo_encoder_use_img_cross_attn,\n",
    "    gpus_to_use=gpus_to_use,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1550465159251583,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import visualize_formatted_frame_output, prepare_masks_for_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this video has 6 objects\n",
    "video_frames_dir = f\"{sam3_root}/assets/videos/0001\"\n",
    "prompt_text_str = \"person\"\n",
    "\n",
    "# this video has ~80 objects\n",
    "# video_frames_dir = \"/checkpoint/sam3/shared/webdemo/data/ta/static/gallery/selected_examples/0018/rgb\"\n",
    "# prompt_text_str = \"horse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \"image_files\" for visualization purposes (they are not used by the model)\n",
    "image_files = glob.glob(os.path.join(video_frames_dir, \"*.jpg\"))\n",
    "try:\n",
    "    # integer sort instead of string sort (so that e.g. \"2.jpg\" is before \"11.jpg\")\n",
    "    image_files.sort(key=lambda p: int(os.path.splitext(os.path.basename(p))[0]))\n",
    "except ValueError:\n",
    "    # fallback to lexicographic sort if the format is not \"<frame_index>.jpg\"\n",
    "    print(\n",
    "        f'frame names are not in \"<frame_index>.jpg\" format: {image_files[:5]=}, '\n",
    "        f\"falling back to lexicographic sort.\"\n",
    "    )\n",
    "    image_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening an inference session on this video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 24791498893803470,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "response = predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"start_session\",\n",
    "        resource_path=video_frames_dir,\n",
    "    )\n",
    ")\n",
    "session_id = response[\"session_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a text prompt on frame 0 and propagation throughout the video\n",
    "\n",
    "Note that the first call might be slower due to setting up buffers. **You can rerun all the cells below when measuring speed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1857140821887322,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "# note: in case you already ran one text prompt and now want to switch to another text prompt\n",
    "# it's required to reset the session first (otherwise the results would be wrong)\n",
    "_ = predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"reset_session\",\n",
    "        session_id=session_id,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1211259840810929,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "frame_idx = 0  # add a text prompt on frame 0\n",
    "response = predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"add_prompt\",\n",
    "        session_id=session_id,\n",
    "        frame_index=frame_idx,\n",
    "        text=prompt_text_str,\n",
    "    )\n",
    ")\n",
    "out = response[\"outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 2176083696212028,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "visualize_formatted_frame_output(\n",
    "    frame_idx,\n",
    "    image_files,\n",
    "    outputs_list=[prepare_masks_for_visualization({frame_idx: out})],\n",
    "    titles=[\"SAM 3 Dense Tracking outputs\"],\n",
    "    figsize=(6, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1292061085723685,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "# we will just propagate from frame 0 to the end of the video\n",
    "outputs_per_frame = {}\n",
    "for response in predictor.handle_stream_request(\n",
    "    request=dict(\n",
    "        type=\"propagate_in_video\",\n",
    "        session_id=session_id,\n",
    "    )\n",
    "):\n",
    "    outputs_per_frame[response[\"frame_index\"]] = response[\"outputs\"]\n",
    "\n",
    "outputs_per_frame = prepare_masks_for_visualization(outputs_per_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "output": {
     "id": 1329493578744396,
     "loadingStatus": "loaded"
    }
   },
   "outputs": [],
   "source": [
    "vis_frame_stride = 60\n",
    "plt.close(\"all\")\n",
    "for frame_idx in range(0, len(outputs_per_frame), vis_frame_stride):\n",
    "    print(f\"frame {frame_idx}\")\n",
    "    visualize_formatted_frame_output(\n",
    "        frame_idx,\n",
    "        image_files,\n",
    "        outputs_list=[outputs_per_frame],\n",
    "        titles=[\"SAM 3 Dense Tracking outputs\"],\n",
    "        figsize=(6, 4),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, close the inference session to free its GPU resources\n",
    "# (you may start a new session on another video)\n",
    "_ = predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"close_session\",\n",
    "        session_id=session_id,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after all inference is done, we can shutdown the predictor\n",
    "# to free up the multi-GPU process group\n",
    "predictor.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileHeader": "",
  "fileUid": "0302644d-89e4-478b-b8e6-568ead852534",
  "isAdHoc": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
