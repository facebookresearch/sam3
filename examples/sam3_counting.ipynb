{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403bfa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c87ecf7",
   "metadata": {},
   "source": [
    "# Counting using SAM3\n",
    "\n",
    "# <a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/sam3/blob/main/notebooks/sam3_counting.ipynb\">\n",
    "#   <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "# </a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b474d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"Torchvision version:\", torchvision.__version__)\n",
    "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install opencv-python matplotlib scikit-learn\n",
    "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/sam3.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from sam3.train.masks_ops import mask_iom\n",
    "from sam3.visualization_utils import plot_mask, COLORS, plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn on tfloat32 for Ampere GPUs\n",
    "# https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# use bfloat16 for the entire notebook\n",
    "torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5346a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_on_image(image, text_prompt, model, processor, output_prob_thresh=0.5):\n",
    "    \"\"\"Run inference on a single image with text prompt\"\"\"\n",
    "    # Create inference state for this image\n",
    "    inference_state = processor(image, instance_prompt=False)\n",
    "\n",
    "    # Add text prompt\n",
    "    processor.reset_all_prompts(inference_state)\n",
    "    processor.add_prompt(inference_state, text_str=text_prompt, instance_prompt=False)\n",
    "\n",
    "    # Run inference\n",
    "    model.run_inference(inference_state)\n",
    "\n",
    "    # Get output with the specified threshold\n",
    "    output = processor.postprocess_output(inference_state, output_prob_thresh=output_prob_thresh)\n",
    "\n",
    "    return output\n",
    "\n",
    "def clean_mask_iom_nms(pred_scores, pred_masks, mask_threshold=0.5, score_thresh=0.5, iou_thresh=0.5):\n",
    "    # Convert numpy arrays to tensors if needed\n",
    "    if isinstance(pred_scores, np.ndarray):\n",
    "        pred_scores = torch.from_numpy(pred_scores)\n",
    "    if isinstance(pred_masks, np.ndarray):\n",
    "        pred_masks = torch.from_numpy(pred_masks)\n",
    "\n",
    "    # Handle different score tensor shapes\n",
    "    if pred_scores.dim() > 1:\n",
    "        scores_flat = pred_scores.squeeze() if pred_scores.shape[-1] == 1 else pred_scores.flatten()\n",
    "    else:\n",
    "        scores_flat = pred_scores\n",
    "\n",
    "    keep = scores_flat >= score_thresh\n",
    "    if keep.sum() < 1:\n",
    "        return pred_scores, pred_masks\n",
    "    maskids = torch.where(keep)[0]\n",
    "\n",
    "    scores_subset = scores_flat[keep]\n",
    "    masks_subset = pred_masks[keep].sigmoid() > mask_threshold\n",
    "\n",
    "    N = masks_subset.size(0)\n",
    "\n",
    "    # sort by score (desc), and compute IoM matrix on the sorted masks\n",
    "    order = scores_subset.argsort(descending=True)\n",
    "    masks_sorted = masks_subset[order]\n",
    "    pairwise_iom = mask_iom(masks_sorted, masks_sorted)\n",
    "\n",
    "    keep_mask = torch.zeros(N, dtype=torch.bool, device=masks_subset.device)\n",
    "    suppressed = torch.zeros(N, dtype=torch.bool, device=masks_subset.device)\n",
    "\n",
    "    for i in range(N):\n",
    "        if suppressed[i]:\n",
    "            continue\n",
    "        keep_mask[i] = True\n",
    "\n",
    "        # suppress all j>i that have IoM > threshold with mask i\n",
    "        sup = pairwise_iom[i] > iou_thresh\n",
    "        # only affect the *future* candidates\n",
    "        if i + 1 < N:\n",
    "            suppressed[i + 1:] |= sup[i + 1:]\n",
    "\n",
    "    # map back to original indices\n",
    "    kept_sorted_idx = torch.nonzero(keep_mask, as_tuple=False).squeeze(1)\n",
    "    maskids_keep_order = order[kept_sorted_idx]\n",
    "    maskids_keep = maskids[maskids_keep_order]\n",
    "\n",
    "    new_scores, new_masks = pred_scores[maskids_keep], pred_masks[maskids_keep]\n",
    "\n",
    "    return new_scores, new_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53cb9ec",
   "metadata": {},
   "source": [
    "### Build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcec42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam3 import build_sam3_image_model\n",
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "\n",
    "\n",
    "sam3_root = \"/home/marksm/sam3\"\n",
    "\n",
    "bpe_path = f\"{sam3_root}/assets/bpe_simple_vocab_16e6.txt.gz\"\n",
    "checkpoint_path = f\"{sam3_root}/assets/checkpoints/checkpoint_model_only_presence_0_5.pt\"\n",
    "\n",
    "model = build_sam3_image_model(bpe_path=bpe_path, checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554cf611",
   "metadata": {},
   "source": [
    "### Counting objects (no post-processing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_prompt = \"person\"\n",
    "image_path = '/checkpoint/sam3/shared/sam3_release/pixmo_count_example.jpg'\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "width, height = image.size\n",
    "processor = Sam3Processor(model, confidence_threshold=0.5)\n",
    "inference_state = processor.set_image(image)\n",
    "inference_state = processor.set_text_prompt(state =inference_state, prompt=text_prompt)\n",
    "\n",
    "plot_results(image, inference_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20fcec8",
   "metadata": {},
   "source": [
    "### Counting objects with IoM NMS\n",
    "\n",
    "We observe that the model predicts 32 instances for this image, while the actual number is 31. Therefore, for the counting task, we further process the outputs using Intersection over Minimum Non-Maximum Suppression (IoM NMS). After applying this method, the number of predicted objects is reduced to 31, which matches the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7353935",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_masks = clean_mask_iom_nms(\n",
    "    inference_state[\"scores\"],\n",
    "    inference_state[\"masks\"].squeeze(1),\n",
    "    mask_threshold=0.5,\n",
    "    score_thresh=0.5,\n",
    "    iou_thresh=0.5\n",
    ")[1]\n",
    "# plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(image)\n",
    "for m_idx, mask in enumerate(binary_masks):\n",
    "    plot_mask(mask.cpu(), color=COLORS[m_idx % len(COLORS)])\n",
    "plt.axis('off')\n",
    "plt.title(f\"IoM NMS Counting Results - {len(binary_masks)} objects found\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
